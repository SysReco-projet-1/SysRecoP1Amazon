# Tâche 3.5.2 : k-NN collaboratif basé utilisateur

## Description

Cette tâche implémente l'algorithme de filtrage collaboratif k-NN (k-Nearest Neighbors) basé utilisateur pour la prédiction des évaluations.

### Formule de prédiction

```
r̂_u,i = r̄_u + Σ(sim(u,v) * (r_v,i - r̄_v)) / Σ|sim(u,v)|
```

Où :
- `r̂_u,i` : Prédiction du rating de l'utilisateur `u` pour l'item `i`
- `r̄_u` : Moyenne des ratings de l'utilisateur `u`
- `N_k(u,i)` : Ensemble des k utilisateurs les plus similaires à `u` ayant évalué l'item `i`
- `sim(u,v)` : Similarité entre les utilisateurs `u` et `v`

## Mesures de similarité implémentées

### 1. Similarité cosinus
```
sim_cos(u,v) = (r_u · r_v) / (||r_u|| ||r_v||)
```

### 2. Corrélation de Pearson
```
sim_pear(u,v) = Σ((r_u,i - r̄_u)(r_v,i - r̄_v)) / √(Σ(r_u,i - r̄_u)² Σ(r_v,i - r̄_v)²)
```

### 3. Similarité de Jaccard
```
sim_jac(u,v) = |I_u ∩ I_v| / |I_u ∪ I_v|
```

## Optimisation des hyperparamètres

Le script teste les configurations suivantes :
- **Valeurs de k** : {10, 20, 30, 50, 100}
- **Mesures de similarité** : cosinus, Pearson, Jaccard

Pour accélérer l'optimisation, un échantillon du test set est utilisé (20% par défaut).

## Gestion des cas limites

1. **Aucun voisin n'a évalué l'item** : Retourne la moyenne de l'utilisateur ou la moyenne de l'item
2. **Moins de k voisins disponibles** : Utilise tous les voisins disponibles
3. **Utilisateur ou item inconnu** : Retourne la moyenne de l'item ou la moyenne globale

## Structure des fichiers

```
step_3_5_2/
├── 3.5.2_knn.py                # Script principal d'optimisation
├── 3.5.2_analysis.py           # Script d'analyse des résultats
└── 3.5.2_README.md             # Ce fichier
```

## Utilisation

### Étape 1 : Optimisation des hyperparamètres

```bash
python step_3_5_2/3.5.2_knn.py
```

Ce script :
- Calcule les 3 matrices de similarité
- Teste toutes les combinaisons (k, similarité)
- Identifie la meilleure configuration
- Sauvegarde les résultats en JSON

### Étape 2 : Analyse des résultats

```bash
python step_3_5_2/3.5.2_analysis.py
```

Ce script :
- Compare k-NN avec les baselines
- Génère des graphiques (RMSE vs k, comparaison des similarités)
- Analyse le compromis précision/temps
- Crée un tableau comparatif complet

## Prérequis

Les fichiers suivants doivent exister :
- `outputs/splits/train_amazon_books_sample_active_users.csv`
- `outputs/splits/test_amazon_books_sample_active_users.csv`
- `outputs/matrice/matcsr_train_amazon_books_sample_active_users.npz`
- `outputs/mappings/user_mapping_train_amazon_books_sample_active_users.csv`
- `outputs/mappings/item_mapping_train_amazon_books_sample_active_users.csv`
- `outputs/step_3_5_1/3.5.1_baselines/baselines_results_50k_active_users.json`

Ces fichiers sont générés par les tâches 3.1.3 (Prétraitement) et 3.5.1 (Baselines).

## Sorties

### Fichiers JSON
- `outputs/step_3_5_2/3.5.2_knn/knn_optimization_50k_active_users.json`
  - Tous les résultats des configurations testées
  - Meilleure configuration identifiée

### Graphiques (générés par 3.5.2_analysis.py)
- `knn_rmse_vs_k.png` : RMSE en fonction de k pour chaque similarité
- `knn_mae_vs_k.png` : MAE en fonction de k pour chaque similarité
- `knn_time_vs_k.png` : Temps d'exécution en fonction de k
- `knn_vs_baselines.png` : Comparaison avec les baselines
- `similarity_comparison.png` : Comparaison des mesures de similarité

## Optimisations computationnelles

1. **Matrices sparse** : Utilisation de `scipy.sparse.csr_matrix` pour économiser la mémoire
2. **Pré-calcul des voisins** : Les k plus proches voisins sont calculés une seule fois
3. **Échantillonnage du test** : Évaluation sur 20% du test set pour accélérer l'optimisation
4. **Vectorisation** : Utilisation de `sklearn.metrics.pairwise` pour les calculs matriciels

## Interprétation des résultats

### Impact de k
- **k faible** (10-20) : Prédictions plus spécifiques mais potentiellement instables
- **k élevé** (50-100) : Prédictions plus stables mais moins personnalisées

### Comparaison des similarités
- **Cosinus** : Rapide, fonctionne bien avec les données sparse
- **Pearson** : Prend en compte les biais utilisateurs (centrage)
- **Jaccard** : Basé uniquement sur les items en commun (ignore les ratings)

### Amélioration vs baselines
Un bon modèle k-NN devrait réduire le RMSE de 5-15% par rapport à la baseline "moyenne par livre".

## Temps d'exécution estimé

Sur un dataset de ~700k évaluations (train) et ~190k (test) :
- Calcul des similarités : 2-5 minutes par mesure
- Pré-calcul des voisins : 10-30 secondes par configuration
- Évaluation sur 20% du test : 30-60 secondes par configuration
- **Total** : ~20-30 minutes pour toutes les configurations

## Stratégies d'accélération

1. **Réduire test_sample_ratio** : Tester sur 10% au lieu de 20%
2. **Limiter les valeurs de k** : Tester seulement {10, 30, 50}
3. **Parallélisation** : Évaluer les similarités en parallèle
4. **Approximation** : Utiliser des méthodes d'approximation (LSH, ANNOY)
