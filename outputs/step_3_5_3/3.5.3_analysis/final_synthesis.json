{
  "title": "Synthèse de l'analyse des résultats - Tâche 3.5",
  "key_findings": [
    {
      "finding": "k-NN surpasse significativement les baselines",
      "details": "Réduction RMSE: 34.9%, Réduction MAE: 44.0%"
    },
    {
      "finding": "Pearson est la meilleure mesure de similarité",
      "details": "Centre les données et élimine les biais utilisateurs"
    },
    {
      "finding": "k=100 offre la meilleure précision",
      "details": "Plus de voisins = prédictions plus stables pour Pearson"
    },
    {
      "finding": "Livres populaires mieux prédits que livres de niche",
      "details": "Plus de données d'entraînement = moyennes plus fiables"
    },
    {
      "finding": "Compromis précision/temps acceptable",
      "details": "~78s pour 12.2% d'amélioration"
    }
  ],
  "recommendations": [
    "Utiliser k-NN avec Pearson et k=100 pour la meilleure précision",
    "Pré-calculer les similarités pour réduire le temps en production",
    "Considérer k=30-50 pour un bon compromis précision/temps",
    "Appliquer des techniques d'approximation (LSH) pour très grandes échelles",
    "Accorder plus d'attention aux livres de niche (cold start problem)"
  ],
  "best_model": {
    "name": "k-NN (k=100, Pearson)",
    "rmse": 0.6309560008590716,
    "mae": 0.4039396969477086,
    "improvement_vs_baseline_rmse_percent": 34.866192773944974,
    "improvement_vs_baseline_mae_percent": 44.00113177843636
  }
}