{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"4f75259c-1ef3-4d7f-b988-25d3fced90ed","_cell_guid":"cf678ed5-00a9-4307-a796-e2cbd718a6ca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T20:40:27.446531Z","iopub.execute_input":"2026-02-14T20:40:27.447084Z","iopub.status.idle":"2026-02-14T20:40:27.779686Z","shell.execute_reply.started":"2026-02-14T20:40:27.447052Z","shell.execute_reply":"2026-02-14T20:40:27.778841Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nINF6083 - Projet P1 : T√¢che 0 - √âchantillonnage Strat√©gique\nBLOC 1 : Configuration et Imports\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport gzip\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nimport os\nimport pickle\nwarnings.filterwarnings('ignore')\n\n# Configuration\nnp.random.seed(42)\nsns.set_style(\"whitegrid\")\n\nprint(\"=\"*70)\nprint(\"√âCHANTILLONNAGE STRAT√âGIQUE - AMAZON BOOKS 2023\")\nprint(\"=\"*70)\n\n# ============================================================================\n# CONFIGURATION DES PARAM√àTRES\n# ============================================================================\nREVIEWS_URL = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/review_categories/Books.jsonl\"\nMETADATA_URL = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/meta_categories/meta_Books.jsonl\"\n\n# Param√®tres d'√©chantillonnage\nMIN_REVIEWS_PER_USER = 20\nTARGET_USERS = 50000\nTARGET_REVIEWS_MIN = 500000\nTARGET_REVIEWS_MAX = 2000000\n\n# Param√®tres temporels\nSTART_YEAR = 2020\nEND_YEAR = 2023\n\n# Fichiers de sauvegarde interm√©diaires\nCHECKPOINT_DIR = \"checkpoints\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\nprint(\"\\n‚úÖ Configuration charg√©e avec succ√®s!\")\nprint(f\"   ‚Ä¢ MIN_REVIEWS_PER_USER: {MIN_REVIEWS_PER_USER}\")\nprint(f\"   ‚Ä¢ TARGET_USERS: {TARGET_USERS:,}\")\nprint(f\"   ‚Ä¢ P√âRIODE TEMPORELLE: {START_YEAR}-{END_YEAR}\")\nprint(f\"   ‚Ä¢ CHECKPOINTS: {CHECKPOINT_DIR}/\")","metadata":{"_uuid":"9f6b42b5-37a5-46de-9a75-258660af3c3b","_cell_guid":"b76b320b-e2f0-4833-b514-fbbddc302f37","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:23:08.062781Z","iopub.execute_input":"2026-02-14T22:23:08.063252Z","iopub.status.idle":"2026-02-14T22:23:10.832344Z","shell.execute_reply.started":"2026-02-14T22:23:08.063221Z","shell.execute_reply":"2026-02-14T22:23:10.831349Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 2 : Fonction de chargement et analyse de l'√©chantillon initial\n\"\"\"\n\nimport requests\n\ndef load_jsonl_streaming(url, max_lines=None, show_progress=True):\n    \"\"\"Charge un fichier JSONL de mani√®re efficace avec streaming\"\"\"\n    print(f\"\\nüì• Chargement depuis: {url}\")\n    \n    response = requests.get(url, stream=True)\n    response.raise_for_status()\n    \n    data = []\n    line_count = 0\n    \n    for line in tqdm(response.iter_lines(decode_unicode=True), desc=\"Lecture\", disable=not show_progress):\n        if not line:\n            continue\n        \n        try:\n            data.append(json.loads(line))\n            line_count += 1\n            \n            if max_lines and line_count >= max_lines:\n                break\n                \n        except json.JSONDecodeError:\n            continue\n    \n    print(f\"‚úÖ {len(data):,} lignes charg√©es\")\n    return pd.DataFrame(data)\n\n# ============================================================================\n# CHARGEMENT √âCHANTILLON INITIAL (skip si d√©j√† fait)\n# ============================================================================\nSAMPLE_FILE = f\"{CHECKPOINT_DIR}/sample_initial.pkl\"\n\nif os.path.exists(SAMPLE_FILE):\n    print(\"\\n‚ôªÔ∏è  √âchantillon initial d√©tect√© - Chargement depuis le checkpoint...\")\n    sample_df = pd.read_pickle(SAMPLE_FILE)\n    print(f\"‚úÖ {len(sample_df):,} lignes charg√©es depuis {SAMPLE_FILE}\")\nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 1: CHARGEMENT DE L'√âCHANTILLON INITIAL\")\n    print(\"=\"*70)\n    \n    sample_df = load_jsonl_streaming(REVIEWS_URL, max_lines=100000)\n    \n    # Sauvegarder le checkpoint\n    sample_df.to_pickle(SAMPLE_FILE)\n    print(f\"\\nüíæ Checkpoint sauvegard√©: {SAMPLE_FILE}\")\n\n# Afficher les infos\nprint(\"\\nüìã Structure des donn√©es:\")\nprint(sample_df.head(3))\nprint(f\"\\nüìè Colonnes: {list(sample_df.columns)}\")\nprint(f\"üìè Lignes: {len(sample_df):,}\")\n\n# V√©rifier format timestamp\nsample_timestamp = sample_df['timestamp'].iloc[0]\nprint(f\"\\nüïê Format timestamp:\")\nif sample_timestamp > 1e12:\n    print(f\"   ‚Ä¢ Format: millisecondes\")\n    print(f\"   ‚Ä¢ Exemple converti: {datetime.fromtimestamp(sample_timestamp/1000).strftime('%Y-%m-%d')}\")\nelse:\n    print(f\"   ‚Ä¢ Format: secondes\")\n    print(f\"   ‚Ä¢ Exemple: {datetime.fromtimestamp(sample_timestamp).strftime('%Y-%m-%d')}\")\n\n# Analyse pr√©liminaire\nuser_counts = sample_df['user_id'].value_counts()\nprint(f\"\\nüìä Statistiques (√©chantillon):\")\nprint(f\"   ‚Ä¢ Utilisateurs uniques: {len(user_counts):,}\")\nprint(f\"   ‚Ä¢ Moyenne reviews/user: {user_counts.mean():.2f}\")\nprint(f\"   ‚Ä¢ M√©diane: {user_counts.median():.0f}\")\nprint(f\"   ‚Ä¢ Utilisateurs ‚â•{MIN_REVIEWS_PER_USER} reviews: {(user_counts >= MIN_REVIEWS_PER_USER).sum():,}\")\n\nprint(\"\\n‚úÖ BLOC 2 TERMIN√â\")","metadata":{"_uuid":"3ef98705-a410-4563-b28e-833d4386f280","_cell_guid":"6325bb83-2096-4a7e-a2d8-c38eb4b830fd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:27:11.330578Z","iopub.execute_input":"2026-02-14T22:27:11.331678Z","iopub.status.idle":"2026-02-14T22:27:12.120230Z","shell.execute_reply.started":"2026-02-14T22:27:11.331638Z","shell.execute_reply":"2026-02-14T22:27:12.119241Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 3 : PASSE 1 - Comptage des √©valuations par utilisateur\n‚è±Ô∏è Dur√©e estim√©e: ~15 minutes\n\"\"\"\n\nUSER_COUNTS_FILE = f\"{CHECKPOINT_DIR}/user_counts.pkl\"\nSELECTED_USERS_FILE = f\"{CHECKPOINT_DIR}/selected_users.pkl\"\n\nif os.path.exists(SELECTED_USERS_FILE):\n    print(\"\\n‚ôªÔ∏è  Utilisateurs d√©j√† s√©lectionn√©s - Skip PASSE 1\")\n    with open(SELECTED_USERS_FILE, 'rb') as f:\n        selected_users = pickle.load(f)\n    print(f\"‚úÖ {len(selected_users):,} utilisateurs charg√©s depuis {SELECTED_USERS_FILE}\")\n    \nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 3: PASSE 1 - COMPTAGE DES UTILISATEURS\")\n    print(\"=\"*70)\n    print(f\"\\nüéØ Objectif: Identifier utilisateurs avec ‚â•{MIN_REVIEWS_PER_USER} √©valuations\")\n    \n    # V√©rifier si le comptage existe d√©j√†\n    if os.path.exists(USER_COUNTS_FILE):\n        print(\"\\n‚ôªÔ∏è  Comptage existant d√©tect√© - Chargement...\")\n        with open(USER_COUNTS_FILE, 'rb') as f:\n            user_review_counts = pickle.load(f)\n        print(f\"‚úÖ {len(user_review_counts):,} utilisateurs charg√©s\")\n    else:\n        print(\"\\nüì• Comptage en cours (peut prendre ~15 minutes)...\")\n        user_review_counts = Counter()\n        \n        response = requests.get(REVIEWS_URL, stream=True)\n        \n        for line in tqdm(response.iter_lines(decode_unicode=True), desc=\"Comptage\"):\n            if not line:\n                continue\n            try:\n                review = json.loads(line)\n                user_review_counts[review['user_id']] += 1\n            except (json.JSONDecodeError, KeyError):\n                continue\n        \n        # Sauvegarder le comptage\n        with open(USER_COUNTS_FILE, 'wb') as f:\n            pickle.dump(user_review_counts, f)\n        print(f\"\\nüíæ Comptage sauvegard√©: {USER_COUNTS_FILE}\")\n        print(f\"‚úÖ {len(user_review_counts):,} utilisateurs uniques\")\n    \n    # Identifier utilisateurs actifs\n    active_users = [user for user, count in user_review_counts.items() \n                    if count >= MIN_REVIEWS_PER_USER]\n    \n    print(f\"\\nüìä Utilisateurs actifs (‚â•{MIN_REVIEWS_PER_USER} reviews): {len(active_users):,}\")\n    \n    # √âchantillonner\n    if len(active_users) > TARGET_USERS:\n        selected_users = set(np.random.choice(active_users, size=TARGET_USERS, replace=False))\n        print(f\"‚úÖ {TARGET_USERS:,} utilisateurs s√©lectionn√©s al√©atoirement\")\n    else:\n        selected_users = set(active_users)\n        print(f\"‚ö†Ô∏è  {len(selected_users):,} utilisateurs disponibles (< {TARGET_USERS:,})\")\n    \n    # Sauvegarder la s√©lection\n    with open(SELECTED_USERS_FILE, 'wb') as f:\n        pickle.dump(selected_users, f)\n    print(f\"üíæ S√©lection sauvegard√©e: {SELECTED_USERS_FILE}\")\n\nprint(f\"\\n‚úÖ BLOC 3 TERMIN√â - {len(selected_users):,} utilisateurs s√©lectionn√©s\")","metadata":{"_uuid":"b8299588-b1ad-4bcd-9f53-c9a1fd72249d","_cell_guid":"5deb6367-0cb0-4dae-92be-44feef3fbb9c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:27:17.245222Z","iopub.execute_input":"2026-02-14T22:27:17.245578Z","iopub.status.idle":"2026-02-14T22:27:17.508498Z","shell.execute_reply.started":"2026-02-14T22:27:17.245550Z","shell.execute_reply":"2026-02-14T22:27:17.507495Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 4 : PASSE 2 - Extraction des √©valuations des utilisateurs s√©lectionn√©s\n‚è±Ô∏è Dur√©e estim√©e: ~12 minutes\n\"\"\"\n\nACTIVE_SAMPLE_FILE = f\"{CHECKPOINT_DIR}/df_active.pkl\"\n\nif os.path.exists(ACTIVE_SAMPLE_FILE):\n    print(\"\\n‚ôªÔ∏è  √âchantillon 'Utilisateurs Actifs' d√©j√† cr√©√© - Skip PASSE 2\")\n    df_active = pd.read_pickle(ACTIVE_SAMPLE_FILE)\n    print(f\"‚úÖ {len(df_active):,} reviews charg√©es depuis {ACTIVE_SAMPLE_FILE}\")\n    \nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 4: PASSE 2 - EXTRACTION DES √âVALUATIONS\")\n    print(\"=\"*70)\n    print(f\"\\nüì• Extraction des reviews de {len(selected_users):,} utilisateurs...\")\n    print(\"‚è±Ô∏è  Dur√©e estim√©e: ~12 minutes\")\n    \n    response = requests.get(REVIEWS_URL, stream=True)\n    sampled_reviews_active = []\n    \n    for line in tqdm(response.iter_lines(decode_unicode=True), desc=\"Extraction\"):\n        if not line:\n            continue\n        try:\n            review = json.loads(line)\n            if review['user_id'] in selected_users:\n                sampled_reviews_active.append(review)\n        except (json.JSONDecodeError, KeyError):\n            continue\n    \n    df_active = pd.DataFrame(sampled_reviews_active)\n    \n    # Convertir timestamps (millisecondes ‚Üí secondes)\n    print(\"\\nüßπ Conversion des timestamps...\")\n    sample_ts = df_active['timestamp'].iloc[0]\n    if sample_ts > 1e12:\n        print(\"   ‚ÑπÔ∏è  Conversion: millisecondes ‚Üí secondes\")\n        df_active['timestamp'] = df_active['timestamp'] / 1000\n    \n    # Filtrer timestamps invalides\n    n_before = len(df_active)\n    mask = (df_active['timestamp'] >= 946684800) & (df_active['timestamp'] <= 1893456000)\n    df_active = df_active[mask].copy()\n    n_after = len(df_active)\n    \n    if n_before != n_after:\n        print(f\"‚ö†Ô∏è  {n_before - n_after:,} timestamps invalides supprim√©s ({((n_before-n_after)/n_before*100):.2f}%)\")\n    \n    # Convertir en ann√©es\n    df_active['year'] = pd.to_datetime(df_active['timestamp'], unit='s').dt.year\n    \n    # Sauvegarder\n    df_active.to_pickle(ACTIVE_SAMPLE_FILE)\n    print(f\"\\nüíæ √âchantillon sauvegard√©: {ACTIVE_SAMPLE_FILE}\")\n\n# Afficher les statistiques\nprint(f\"\\n‚úÖ √âCHANTILLON 'UTILISATEURS ACTIFS':\")\nprint(f\"   ‚Ä¢ Reviews: {len(df_active):,}\")\nprint(f\"   ‚Ä¢ Utilisateurs: {df_active['user_id'].nunique():,}\")\nprint(f\"   ‚Ä¢ Livres: {df_active['parent_asin'].nunique():,}\")\nprint(f\"   ‚Ä¢ P√©riode: {df_active['year'].min()} - {df_active['year'].max()}\")\nprint(f\"   ‚Ä¢ Rating moyen: {df_active['rating'].mean():.2f}\")\n\nprint(\"\\n‚úÖ BLOC 4 TERMIN√â\")","metadata":{"_uuid":"d89e4c40-c1f8-453f-a7c1-180916f0efa3","_cell_guid":"dcb7fbd9-cf45-4b6a-8e29-33f5765d0083","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:27:23.741573Z","iopub.execute_input":"2026-02-14T22:27:23.741874Z","iopub.status.idle":"2026-02-14T22:27:36.205355Z","shell.execute_reply.started":"2026-02-14T22:27:23.741849Z","shell.execute_reply":"2026-02-14T22:27:36.204435Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 5 : √âchantillonnage temporel (2020-2023)\n‚è±Ô∏è Dur√©e estim√©e: ~3 minutes\n‚ö†Ô∏è  OPTIONNEL - Peut √™tre skipp√© si vous voulez seulement la strat√©gie 1\n\"\"\"\n\nTEMPORAL_SAMPLE_FILE = f\"{CHECKPOINT_DIR}/df_temporal.pkl\"\n\n# Demander confirmation avant de lancer (car prend du temps)\nRUN_TEMPORAL = True  # Mettre False pour skip\n\nif not RUN_TEMPORAL:\n    print(\"\\n‚è≠Ô∏è  BLOC 5 SKIPP√â (√©chantillonnage temporel d√©sactiv√©)\")\n    df_temporal = pd.DataFrame()  # DataFrame vide\n    \nelif os.path.exists(TEMPORAL_SAMPLE_FILE):\n    print(\"\\n‚ôªÔ∏è  √âchantillon temporel d√©j√† cr√©√© - Skip\")\n    df_temporal = pd.read_pickle(TEMPORAL_SAMPLE_FILE)\n    print(f\"‚úÖ {len(df_temporal):,} reviews charg√©es depuis {TEMPORAL_SAMPLE_FILE}\")\n    \nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 5: √âCHANTILLONNAGE TEMPOREL\")\n    print(\"=\"*70)\n    print(f\"\\nüéØ Objectif: Reviews de {START_YEAR} √† {END_YEAR}\")\n    \n    # Timestamps en millisecondes\n    start_ts_ms = datetime(START_YEAR, 1, 1).timestamp() * 1000\n    end_ts_ms = datetime(END_YEAR + 1, 1, 1).timestamp() * 1000\n    \n    print(f\"\\nüì• Filtrage temporel en cours...\")\n    \n    response = requests.get(REVIEWS_URL, stream=True)\n    sampled_reviews_temporal = []\n    \n    for line in tqdm(response.iter_lines(decode_unicode=True), desc=\"Filtrage\"):\n        if not line:\n            continue\n        try:\n            review = json.loads(line)\n            timestamp = review.get('timestamp', 0)\n            if start_ts_ms <= timestamp < end_ts_ms:\n                sampled_reviews_temporal.append(review)\n        except (json.JSONDecodeError, KeyError):\n            continue\n    \n    df_temporal = pd.DataFrame(sampled_reviews_temporal)\n    \n    if len(df_temporal) > 0:\n        # Convertir timestamps\n        df_temporal['timestamp'] = df_temporal['timestamp'] / 1000\n        df_temporal['year'] = pd.to_datetime(df_temporal['timestamp'], unit='s').dt.year\n        \n        # Sauvegarder\n        df_temporal.to_pickle(TEMPORAL_SAMPLE_FILE)\n        print(f\"\\nüíæ √âchantillon temporel sauvegard√©: {TEMPORAL_SAMPLE_FILE}\")\n    else:\n        print(\"\\n‚ö†Ô∏è  Aucune donn√©e trouv√©e pour cette p√©riode\")\n\n# Afficher statistiques\nif len(df_temporal) > 0:\n    print(f\"\\n‚úÖ √âCHANTILLON TEMPOREL:\")\n    print(f\"   ‚Ä¢ Reviews: {len(df_temporal):,}\")\n    print(f\"   ‚Ä¢ Utilisateurs: {df_temporal['user_id'].nunique():,}\")\n    print(f\"   ‚Ä¢ Livres: {df_temporal['parent_asin'].nunique():,}\")\n    print(f\"   ‚Ä¢ P√©riode: {df_temporal['year'].min()} - {df_temporal['year'].max()}\")\nelse:\n    print(\"\\n‚ö†Ô∏è  Pas d'√©chantillon temporel disponible\")\n\nprint(\"\\n‚úÖ BLOC 5 TERMIN√â\")","metadata":{"_uuid":"552b167d-8ceb-4d71-867b-7ec88cc5f2bd","_cell_guid":"2e38f9aa-c47d-4038-ad33-69cfae861b0a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:27:36.207059Z","iopub.execute_input":"2026-02-14T22:27:36.207374Z","iopub.status.idle":"2026-02-14T22:27:57.918621Z","shell.execute_reply.started":"2026-02-14T22:27:36.207347Z","shell.execute_reply":"2026-02-14T22:27:57.917590Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 6 : Comparaison des strat√©gies et recommandation\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 6: COMPARAISON ET RECOMMANDATION\")\nprint(\"=\"*70)\n\n# Tableau comparatif\ncomparison_data = {\n    'M√©trique': [\n        'Nombre de reviews',\n        'Nombre d\\'utilisateurs',\n        'Nombre de livres',\n        'Reviews/utilisateur (moy)',\n        'Reviews/livre (moy)',\n        'Taux de sparsit√© (%)'\n    ],\n    'Utilisateurs Actifs': [\n        f\"{len(df_active):,}\",\n        f\"{df_active['user_id'].nunique():,}\",\n        f\"{df_active['parent_asin'].nunique():,}\",\n        f\"{len(df_active) / df_active['user_id'].nunique():.2f}\",\n        f\"{len(df_active) / df_active['parent_asin'].nunique():.2f}\",\n        f\"{(1 - len(df_active) / (df_active['user_id'].nunique() * df_active['parent_asin'].nunique())) * 100:.4f}\"\n    ]\n}\n\nif len(df_temporal) > 0:\n    comparison_data['Temporel'] = [\n        f\"{len(df_temporal):,}\",\n        f\"{df_temporal['user_id'].nunique():,}\",\n        f\"{df_temporal['parent_asin'].nunique():,}\",\n        f\"{len(df_temporal) / df_temporal['user_id'].nunique():.2f}\",\n        f\"{len(df_temporal) / df_temporal['parent_asin'].nunique():.2f}\",\n        f\"{(1 - len(df_temporal) / (df_temporal['user_id'].nunique() * df_temporal['parent_asin'].nunique())) * 100:.4f}\"\n    ]\nelse:\n    comparison_data['Temporel'] = ['N/A'] * 6\n\ncomparison_df = pd.DataFrame(comparison_data)\nprint(\"\\nüìä TABLEAU COMPARATIF:\")\nprint(comparison_df.to_string(index=False))\n\n# Justification\nprint(\"\\nüìù JUSTIFICATION DES STRAT√âGIES:\")\nprint(\"\\n1Ô∏è‚É£ STRAT√âGIE UTILISATEURS ACTIFS:\")\nprint(\"   ‚úÖ Avantages:\")\nprint(\"      ‚Ä¢ Garantit des utilisateurs avec profils riches\")\nprint(\"      ‚Ä¢ R√©duit la sparsit√© de la matrice\")\nprint(\"      ‚Ä¢ Facilite le calcul de similarit√©s\")\nprint(\"      ‚Ä¢ Volum√©trie contr√¥l√©e et pr√©visible\")\nprint(\"   ‚ö†Ô∏è  Inconv√©nients:\")\nprint(\"      ‚Ä¢ Biais vers les 'power users'\")\nprint(\"      ‚Ä¢ Moins repr√©sentatif de l'utilisateur moyen\")\n\nprint(\"\\n2Ô∏è‚É£ STRAT√âGIE TEMPORELLE:\")\nprint(\"   ‚úÖ Avantages:\")\nprint(\"      ‚Ä¢ Donn√©es r√©centes et pertinentes\")\nprint(\"      ‚Ä¢ Moins de biais de s√©lection\")\nprint(\"      ‚Ä¢ Refl√®te les tendances actuelles\")\nprint(\"   ‚ö†Ô∏è  Inconv√©nients:\")\nprint(\"      ‚Ä¢ Volum√©trie variable selon la p√©riode\")\nprint(\"      ‚Ä¢ Beaucoup d'utilisateurs occasionnels\")\n\n# Recommandation\nactive_in_range = TARGET_REVIEWS_MIN <= len(df_active) <= TARGET_REVIEWS_MAX\ntemporal_in_range = len(df_temporal) > 0 and TARGET_REVIEWS_MIN <= len(df_temporal) <= TARGET_REVIEWS_MAX\n\nprint(\"\\nüéØ RECOMMANDATION:\")\nif active_in_range:\n    recommended = \"Utilisateurs Actifs\"\n    print(f\"   ‚úÖ Strat√©gie recommand√©e: {recommended}\")\n    print(f\"   ‚Ä¢ Volum√©trie dans la cible ({TARGET_REVIEWS_MIN:,} - {TARGET_REVIEWS_MAX:,})\")\n    final_df = df_active\n    strategy_name = \"active_users\"\nelif temporal_in_range:\n    recommended = \"Temporelle\"\n    print(f\"   ‚úÖ Strat√©gie recommand√©e: {recommended}\")\n    final_df = df_temporal\n    strategy_name = \"temporal\"\nelse:\n    print(f\"   ‚ö†Ô∏è  Aucune strat√©gie n'atteint exactement la cible\")\n    print(f\"   ‚Ä¢ Recommandation par d√©faut: Utilisateurs Actifs\")\n    final_df = df_active\n    strategy_name = \"active_users\"\n\nprint(f\"\\n‚úÖ Strat√©gie finale: {strategy_name.upper()}\")\nprint(\"\\n‚úÖ BLOC 6 TERMIN√â\")","metadata":{"_uuid":"690fecfb-aa24-40d0-a448-64ada6ba0c8d","_cell_guid":"e8f1e781-ff02-4dc0-b8c9-ccf2811bd7f9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:28:00.953152Z","iopub.execute_input":"2026-02-14T22:28:00.953492Z","iopub.status.idle":"2026-02-14T22:28:15.111696Z","shell.execute_reply.started":"2026-02-14T22:28:00.953464Z","shell.execute_reply":"2026-02-14T22:28:15.110645Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 7 : Sauvegarde des fichiers finaux (CSV + JSON)\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 7: SAUVEGARDE DES FICHIERS FINAUX\")\nprint(\"=\"*70)\n\n# Sauvegarder les √©chantillons CSV\nprint(\"\\nüíæ Sauvegarde des fichiers CSV...\")\n\ndf_active.to_csv(\"amazon_books_sample_active_users.csv\", index=False)\nprint(f\"‚úÖ amazon_books_sample_active_users.csv ({len(df_active):,} lignes)\")\n\nif len(df_temporal) > 0:\n    df_temporal.to_csv(\"amazon_books_sample_temporal.csv\", index=False)\n    print(f\"‚úÖ amazon_books_sample_temporal.csv ({len(df_temporal):,} lignes)\")\n\n# Fichier recommand√©\noutput_file = f\"amazon_books_sample_{strategy_name}.csv\"\nfinal_df.to_csv(output_file, index=False)\nprint(f\"‚úÖ {output_file} (recommand√©) ({len(final_df):,} lignes)\")\n\n# M√©tadonn√©es JSON\nmetadata = {\n    'date_creation': datetime.now().isoformat(),\n    'strategie_recommandee': strategy_name,\n    'parametres': {\n        'min_reviews_per_user': MIN_REVIEWS_PER_USER,\n        'target_users': TARGET_USERS,\n        'target_reviews_range': [TARGET_REVIEWS_MIN, TARGET_REVIEWS_MAX],\n        'temporal_range': [START_YEAR, END_YEAR]\n    },\n    'resultats': {\n        'active_users': {\n            'n_reviews': len(df_active),\n            'n_users': int(df_active['user_id'].nunique()),\n            'n_items': int(df_active['parent_asin'].nunique()),\n            'periode': f\"{df_active['year'].min()}-{df_active['year'].max()}\",\n            'sparsity': float((1 - len(df_active) / (df_active['user_id'].nunique() * df_active['parent_asin'].nunique())) * 100)\n        },\n        'temporal': {\n            'n_reviews': len(df_temporal) if len(df_temporal) > 0 else 0,\n            'n_users': int(df_temporal['user_id'].nunique()) if len(df_temporal) > 0 else 0,\n            'n_items': int(df_temporal['parent_asin'].nunique()) if len(df_temporal) > 0 else 0,\n            'periode': f\"{df_temporal['year'].min()}-{df_temporal['year'].max()}\" if len(df_temporal) > 0 else \"N/A\"\n        }\n    }\n}\n\nwith open('sampling_metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\nprint(\"‚úÖ sampling_metadata.json\")\n\nprint(\"\\nüìÅ FICHIERS G√âN√âR√âS:\")\nprint(\"   ‚Ä¢ amazon_books_sample_active_users.csv\")\nif len(df_temporal) > 0:\n    print(\"   ‚Ä¢ amazon_books_sample_temporal.csv\")\nprint(f\"   ‚Ä¢ {output_file} (recommand√©)\")\nprint(\"   ‚Ä¢ sampling_metadata.json\")\n\nprint(\"\\n‚úÖ BLOC 7 TERMIN√â\")","metadata":{"_uuid":"8879900c-64b4-4779-8a19-cd4201ca17e7","_cell_guid":"d9b6c9b8-4f4b-4431-83cb-02f4dd2ba8b4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:50:12.717900Z","iopub.execute_input":"2026-02-14T22:50:12.718955Z","iopub.status.idle":"2026-02-14T22:55:06.322960Z","shell.execute_reply.started":"2026-02-14T22:50:12.718922Z","shell.execute_reply":"2026-02-14T22:55:06.321410Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBLOC 8 : Visualisations et rapport final\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 8: VISUALISATIONS ET RAPPORT FINAL\")\nprint(\"=\"*70)\n\n# Cr√©er les visualisations\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# 1. Distribution des ratings\naxes[0, 0].hist(final_df['rating'], bins=5, edgecolor='black', alpha=0.7, color='steelblue')\naxes[0, 0].set_xlabel('Rating', fontsize=11)\naxes[0, 0].set_ylabel('Fr√©quence', fontsize=11)\naxes[0, 0].set_title('Distribution des √âvaluations', fontsize=12, fontweight='bold')\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. Reviews par utilisateur\nuser_review_dist = final_df['user_id'].value_counts()\naxes[0, 1].hist(user_review_dist, bins=50, edgecolor='black', alpha=0.7, color='coral')\naxes[0, 1].set_xlabel('Nombre de reviews par utilisateur', fontsize=11)\naxes[0, 1].set_ylabel('Fr√©quence', fontsize=11)\naxes[0, 1].set_title('Distribution: Reviews par Utilisateur', fontsize=12, fontweight='bold')\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. Reviews par livre (top 50)\nbook_review_dist = final_df['parent_asin'].value_counts().head(50)\naxes[1, 0].bar(range(len(book_review_dist)), book_review_dist.values, alpha=0.7, color='seagreen')\naxes[1, 0].set_xlabel('Livres (top 50)', fontsize=11)\naxes[1, 0].set_ylabel('Nombre de reviews', fontsize=11)\naxes[1, 0].set_title('Distribution: Reviews par Livre (Top 50)', fontsize=12, fontweight='bold')\naxes[1, 0].grid(True, alpha=0.3, axis='y')\n\n# 4. Distribution temporelle\nyear_dist = final_df['year'].value_counts().sort_index()\naxes[1, 1].plot(year_dist.index, year_dist.values, marker='o', linewidth=2, \n                markersize=8, color='purple')\naxes[1, 1].set_xlabel('Ann√©e', fontsize=11)\naxes[1, 1].set_ylabel('Nombre de reviews', fontsize=11)\naxes[1, 1].set_title('Distribution Temporelle', fontsize=12, fontweight='bold')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.savefig('sampling_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n‚úÖ Visualisation sauvegard√©e: sampling_analysis.png\")\nplt.show()\n\n# Rapport final\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìä RAPPORT FINAL\")\nprint(\"=\"*70)\n\nprint(f\"\\nüéØ √âCHANTILLON FINAL ({strategy_name.upper()}):\")\nprint(f\"   ‚Ä¢ Nombre de reviews: {len(final_df):,}\")\nprint(f\"   ‚Ä¢ Utilisateurs uniques: {final_df['user_id'].nunique():,}\")\nprint(f\"   ‚Ä¢ Livres uniques: {final_df['parent_asin'].nunique():,}\")\nprint(f\"   ‚Ä¢ Taux de sparsit√©: {(1 - len(final_df) / (final_df['user_id'].nunique() * final_df['parent_asin'].nunique())) * 100:.4f}%\")\nprint(f\"   ‚Ä¢ Rating moyen: {final_df['rating'].mean():.2f}\")\nprint(f\"   ‚Ä¢ √âcart-type rating: {final_df['rating'].std():.2f}\")\nprint(f\"   ‚Ä¢ P√©riode: {final_df['year'].min()} - {final_df['year'].max()}\")\n\nprint(\"\\nüìà M√âTRIQUES PAR UTILISATEUR:\")\nreviews_per_user = final_df['user_id'].value_counts()\nprint(f\"   ‚Ä¢ Moyenne: {reviews_per_user.mean():.2f} reviews/utilisateur\")\nprint(f\"   ‚Ä¢ M√©diane: {reviews_per_user.median():.0f}\")\nprint(f\"   ‚Ä¢ Min: {reviews_per_user.min()}\")\nprint(f\"   ‚Ä¢ Max: {reviews_per_user.max()}\")\n\nprint(\"\\nüìö M√âTRIQUES PAR LIVRE:\")\nreviews_per_book = final_df['parent_asin'].value_counts()\nprint(f\"   ‚Ä¢ Moyenne: {reviews_per_book.mean():.2f} reviews/livre\")\nprint(f\"   ‚Ä¢ M√©diane: {reviews_per_book.median():.0f}\")\nprint(f\"   ‚Ä¢ Min: {reviews_per_book.min()}\")\nprint(f\"   ‚Ä¢ Max: {reviews_per_book.max()}\")\n\nprint(\"\\n‚≠ê DISTRIBUTION DES RATINGS:\")\nfor rating in sorted(final_df['rating'].unique()):\n    count = (final_df['rating'] == rating).sum()\n    pct = count / len(final_df) * 100\n    print(f\"   ‚Ä¢ {rating:.0f} √©toiles: {count:,} ({pct:.1f}%)\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ √âCHANTILLONNAGE STRAT√âGIQUE TERMIN√â AVEC SUCC√àS!\")\nprint(\"=\"*70)\n\nprint(\"\\nüì¶ FICHIERS FINAUX G√âN√âR√âS:\")\nprint(\"   1. amazon_books_sample_active_users.csv\")\nif len(df_temporal) > 0:\n    print(\"   2. amazon_books_sample_temporal.csv\")\nprint(f\"   3. {output_file} (recommand√©)\")\nprint(\"   4. sampling_metadata.json\")\nprint(\"   5. sampling_analysis.png\")\nprint(f\"\\nüìÅ Checkpoints interm√©diaires: {CHECKPOINT_DIR}/\")\n\nprint(\"\\n‚úÖ BLOC 8 TERMIN√â - FIN DU SCRIPT\")","metadata":{"_uuid":"a33a65de-b347-4aa3-bac5-881840980711","_cell_guid":"a56868ce-0fca-4e64-ba2c-2b15e3ba3153","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-02-14T22:55:29.134975Z","iopub.execute_input":"2026-02-14T22:55:29.135848Z","iopub.status.idle":"2026-02-14T22:55:37.459391Z","shell.execute_reply.started":"2026-02-14T22:55:29.135813Z","shell.execute_reply":"2026-02-14T22:55:37.458326Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}